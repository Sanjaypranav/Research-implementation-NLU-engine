{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./../../../data/test/vectorizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0        these tiktoks radiate gay chaotic energy and i...\n1        @Champions Again He got killed for using false...\n2                     It's not that all lives don't matter\n3        Is it really that difficult to understand? Bla...\n4        Whenever we say black isn't that racists?  Why...\n                               ...                        \n22857    @D You are a fascist if you feel the need to d...\n22858    I think we missed the biggest story here. That...\n22859    100%. These people make their community and ca...\n22860    I dont think the fact that she disagrees means...\n22861      As long as she doesnt get too near the radiator\nName: text, Length: 22862, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  these tiktoks radiate gay chaotic energy and i love it\n",
      "-  @Champions Again He got killed for using false money\n",
      "-  It's not that all lives don't matter\n",
      "-  Is it really that difficult to understand? Black lives matter and all lives matter are not mutually exclusive. They are both true as general statements. So are white lives matter and asian lives matter. Black lives matter in this context is simply the name of a movement against the strangely high rate of police violence on black people and the statement is referring to those who behave like and treat black people as if they dont matter. For example\n",
      "-  Whenever we say black isn't that racists?  Why don't just say Americans.\n",
      "-  Ros The Boss u don’t know that she’s actually lgbtq tho so....\n",
      "-  That was funny at the end when Larry said 'What are we arguing about then'. haha but that said\n",
      "-  She saves lives with her music.\n",
      "-  There were a lot of Samoans in my Army unit\n",
      "-  Network Engineer here- 23 and currently working as an instructor teaching men and women looking to be in IT =] Next I want to teach at a University!\n"
     ]
    }
   ],
   "source": [
    "for text in data.text[:10]:\n",
    "    print(\"- \",text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def train(cv: CountVectorizer, data):\n",
    "    cv.fit(data.text[:1000])\n",
    "    a = cv.transform(data.text[:1000])\n",
    "\n",
    "    Count_array = a.toarray()\n",
    "\n",
    "    cv.get_feature_names_out()\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(Count_array, data.label[:1000])\n",
    "    nb.score(Count_array, data.label[:1000])\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Count_array, data.label[:1000], test_size=0.2, random_state=30)\n",
    "\n",
    "    nb_test_train = GaussianNB()\n",
    "    nb_test_train.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Training accuracy: \",nb_test_train.score(X_train, y_train))\n",
    "\n",
    "    print(\"Testing accuracy: \", nb_test_train.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.99375\n",
      "Testing accuracy:  0.83\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,3))\n",
    "train(cv, data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.95\n",
      "Testing accuracy:  0.785\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "train(cv, data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.99375\n",
      "Testing accuracy:  0.83\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,4))\n",
    "train(cv, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.99375\n",
      "Testing accuracy:  0.83\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,4), stop_words=['english'])\n",
    "train(cv, data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-03 12:58:18--  http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words\r\n",
      "wget: Cannot read /Users/prakashramesh/.netrc (Permission denied).\r\n",
      "Resolving ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)... 130.209.240.253\r\n",
      "Connecting to ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)|130.209.240.253|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2237 (2.2K)\r\n",
      "Saving to: ‘stop_words’\r\n",
      "\r\n",
      "stop_words          100%[===================>]   2.18K  --.-KB/s    in 0.01s   \r\n",
      "\r\n",
      "2022-01-03 12:58:18 (171 KB/s) - ‘stop_words’ saved [2237/2237]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with open(\"stop_words\") as f:\n",
    "    stop_words = f.read()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "words = stop_words.split('\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.96375\n",
      "Testing accuracy:  0.79\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,4), stop_words=words)\n",
    "train(cv, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "analyser = cv.build_analyzer()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "['hi', 'hello', 'hi hello']"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser(\"hi hello\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "\n",
    "tok = cv. ()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "['hi', 'ello']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok(\"hi ello\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method CountVectorizer.get_feature_names of CountVectorizer(ngram_range=(1, 4),\n                stop_words=['a', 'about', 'above', 'across', 'after',\n                            'afterwards', 'again', 'against', 'all', 'almost',\n                            'alone', 'along', 'already', 'also', 'although',\n                            'always', 'am', 'among', 'amongst', 'amoungst',\n                            'amount', 'an', 'and', 'another', 'any', 'anyhow',\n                            'anyone', 'anything', 'anyway', 'anywhere', ...])>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{'analyzer': 'word',\n 'binary': False,\n 'decode_error': 'strict',\n 'dtype': numpy.int64,\n 'encoding': 'utf-8',\n 'input': 'content',\n 'lowercase': True,\n 'max_df': 1.0,\n 'max_features': None,\n 'min_df': 1,\n 'ngram_range': (1, 4),\n 'preprocessor': None,\n 'stop_words': ['a',\n  'about',\n  'above',\n  'across',\n  'after',\n  'afterwards',\n  'again',\n  'against',\n  'all',\n  'almost',\n  'alone',\n  'along',\n  'already',\n  'also',\n  'although',\n  'always',\n  'am',\n  'among',\n  'amongst',\n  'amoungst',\n  'amount',\n  'an',\n  'and',\n  'another',\n  'any',\n  'anyhow',\n  'anyone',\n  'anything',\n  'anyway',\n  'anywhere',\n  'are',\n  'around',\n  'as',\n  'at',\n  'back',\n  'be',\n  'became',\n  'because',\n  'become',\n  'becomes',\n  'becoming',\n  'been',\n  'before',\n  'beforehand',\n  'behind',\n  'being',\n  'below',\n  'beside',\n  'besides',\n  'between',\n  'beyond',\n  'bill',\n  'both',\n  'bottom',\n  'but',\n  'by',\n  'call',\n  'can',\n  'cannot',\n  'cant',\n  'co',\n  'computer',\n  'con',\n  'could',\n  'couldnt',\n  'cry',\n  'de',\n  'describe',\n  'detail',\n  'do',\n  'done',\n  'down',\n  'due',\n  'during',\n  'each',\n  'eg',\n  'eight',\n  'either',\n  'eleven',\n  'else',\n  'elsewhere',\n  'empty',\n  'enough',\n  'etc',\n  'even',\n  'ever',\n  'every',\n  'everyone',\n  'everything',\n  'everywhere',\n  'except',\n  'few',\n  'fifteen',\n  'fify',\n  'fill',\n  'find',\n  'fire',\n  'first',\n  'five',\n  'for',\n  'former',\n  'formerly',\n  'forty',\n  'found',\n  'four',\n  'from',\n  'front',\n  'full',\n  'further',\n  'get',\n  'give',\n  'go',\n  'had',\n  'has',\n  'hasnt',\n  'have',\n  'he',\n  'hence',\n  'her',\n  'here',\n  'hereafter',\n  'hereby',\n  'herein',\n  'hereupon',\n  'hers',\n  'herself',\n  'him',\n  'himself',\n  'his',\n  'how',\n  'however',\n  'hundred',\n  'i',\n  'ie',\n  'if',\n  'in',\n  'inc',\n  'indeed',\n  'interest',\n  'into',\n  'is',\n  'it',\n  'its',\n  'itself',\n  'keep',\n  'last',\n  'latter',\n  'latterly',\n  'least',\n  'less',\n  'ltd',\n  'made',\n  'many',\n  'may',\n  'me',\n  'meanwhile',\n  'might',\n  'mill',\n  'mine',\n  'more',\n  'moreover',\n  'most',\n  'mostly',\n  'move',\n  'much',\n  'must',\n  'my',\n  'myself',\n  'name',\n  'namely',\n  'neither',\n  'never',\n  'nevertheless',\n  'next',\n  'nine',\n  'no',\n  'nobody',\n  'none',\n  'noone',\n  'nor',\n  'not',\n  'nothing',\n  'now',\n  'nowhere',\n  'of',\n  'off',\n  'often',\n  'on',\n  'once',\n  'one',\n  'only',\n  'onto',\n  'or',\n  'other',\n  'others',\n  'otherwise',\n  'our',\n  'ours',\n  'ourselves',\n  'out',\n  'over',\n  'own',\n  'part',\n  'per',\n  'perhaps',\n  'please',\n  'put',\n  'rather',\n  're',\n  'same',\n  'see',\n  'seem',\n  'seemed',\n  'seeming',\n  'seems',\n  'serious',\n  'several',\n  'she',\n  'should',\n  'show',\n  'side',\n  'since',\n  'sincere',\n  'six',\n  'sixty',\n  'so',\n  'some',\n  'somehow',\n  'someone',\n  'something',\n  'sometime',\n  'sometimes',\n  'somewhere',\n  'still',\n  'such',\n  'system',\n  'take',\n  'ten',\n  'than',\n  'that',\n  'the',\n  'their',\n  'them',\n  'themselves',\n  'then',\n  'thence',\n  'there',\n  'thereafter',\n  'thereby',\n  'therefore',\n  'therein',\n  'thereupon',\n  'these',\n  'they',\n  'thick',\n  'thin',\n  'third',\n  'this',\n  'those',\n  'though',\n  'three',\n  'through',\n  'throughout',\n  'thru',\n  'thus',\n  'to',\n  'together',\n  'too',\n  'top',\n  'toward',\n  'towards',\n  'twelve',\n  'twenty',\n  'two',\n  'un',\n  'under',\n  'until',\n  'up',\n  'upon',\n  'us',\n  'very',\n  'via',\n  'was',\n  'we',\n  'well',\n  'were',\n  'what',\n  'whatever',\n  'when',\n  'whence',\n  'whenever',\n  'where',\n  'whereafter',\n  'whereas',\n  'whereby',\n  'wherein',\n  'whereupon',\n  'wherever',\n  'whether',\n  'which',\n  'while',\n  'whither',\n  'who',\n  'whoever',\n  'whole',\n  'whom',\n  'whose',\n  'why',\n  'will',\n  'with',\n  'within',\n  'without',\n  'would',\n  'yet',\n  'you',\n  'your',\n  'yours',\n  'yourself',\n  'yourselves',\n  ''],\n 'strip_accents': None,\n 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n 'tokenizer': None,\n 'vocabulary': None}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'utf-8'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.encoding\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hi - greet\n",
    "\n",
    "# twitter:\n",
    "#     you are a fool - Hate\n",
    "#     These guys are amazing - Non-hate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# #ajith #valimai\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}